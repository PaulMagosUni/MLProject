{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76221a5d468b33a8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ML Cup Dataset\n",
    "In this notebook we perform model training, selection and assessment over the ML Cup Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f565beeebe055d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:43:58.824601Z",
     "start_time": "2024-01-09T16:43:58.787127Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from exclusiveAI.components.Validation.HoldOut import parallel_hold_out\n",
    "from exclusiveAI.components.Validation.KFoldCrossValidation import validate\n",
    "from exclusiveAI.ConfiguratorGen import ConfiguratorGen\n",
    "from exclusiveAI.datasets.mlcup import read_cup_training_dataset, read_cup_test_dataset\n",
    "from exclusiveAI.Composer import Composer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exclusiveAI.utils import plot_history\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec16118",
   "metadata": {},
   "source": [
    "## Read Dataset \n",
    "Importing training and test dataset by splitting data and test labels. Saving indexes too for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efbf06487c3d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:43:58.824874Z",
     "start_time": "2024-01-09T16:43:58.792099Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"MLCup/Data/training_data_split.json\"\n",
    "# Load training and test data from the JSON file\n",
    "with open(file_path, 'r') as jsonfile:\n",
    "    data_dict = json.load(jsonfile)\n",
    "\n",
    "training_data = np.array(data_dict['training_data'])\n",
    "training_labels = np.array(data_dict['training_labels'])\n",
    "test_data = np.array(data_dict['test_data'])\n",
    "test_labels = np.array(data_dict['test_labels'])\n",
    "train_idx = np.array(data_dict['train_idx'])\n",
    "test_idx = np.array(data_dict['test_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad65f6",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "After having performed a coarse-grained grid search, we perform a fine-grained grid search using the combination of best model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0e2c52c8aea4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:43:58.874480Z",
     "start_time": "2024-01-09T16:43:58.830125Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_json_files(my_dir_path):\n",
    "        data = pd.DataFrame()\n",
    "        for file in os.listdir(my_dir_path):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(my_dir_path, file), 'r') as f:\n",
    "                    my_data = [data['0'] for data in json.load(f).values()][1]\n",
    "                    data = pd.concat([data,  pd.DataFrame(my_data)], ignore_index=True, axis=0)\n",
    "        return data\n",
    "batch_size = 200\n",
    "epochs = 1000\n",
    "\n",
    "final_path = 'MLCup_models_configs1520.json'\n",
    "\n",
    "if not os.path.exists(final_path):\n",
    "    dir_path = \"MLCup/\"\n",
    "    \n",
    "    all_json_data = read_json_files(dir_path)\n",
    "    # Get the top 3 most common values\n",
    "    # regularizations = all_json_data['regularization'].unique().tolist()\n",
    "    regularizations = [1e-6, 1e-7, 1e-8]\n",
    "    learning_rates = [0.001, 0.0005]\n",
    "    momentums = [0.5]\n",
    "    num_of_layers = [2]\n",
    "    # num_of_units = set([unit1 for unit in all_json_data['num_of_units'] for unit1 in unit])\n",
    "    num_of_units = [15, 20]\n",
    "    initializers = all_json_data['initializers'].unique().tolist()\n",
    "    activations = ['tanh', 'sigmoid']\n",
    "\n",
    "    myConfigurator = ConfiguratorGen(random=False, learning_rates=learning_rates, regularizations=regularizations,\n",
    "                                     loss_function=['mse'], optimizer=['sgd'],\n",
    "                                     activation_functions=activations,\n",
    "                                     number_of_units=num_of_units, number_of_layers=num_of_layers,\n",
    "                                     momentums=momentums, initializers=initializers,\n",
    "                                     input_shapes=training_data.shape,\n",
    "                                     verbose=False, nesterov=False, outputs=3,\n",
    "                                     callbacks=[\"earlystopping\"], output_activation='linear', show_line=False,\n",
    "                                     ).get_configs()\n",
    "    print(len(myConfigurator))\n",
    "    \n",
    "    configs=[]\n",
    "    if __name__ == '__main__':\n",
    "        configs.append(\n",
    "            parallel_hold_out(myConfigurator, training=training_data, training_target=training_labels, epochs=epochs, return_models_history=True,\n",
    "                              batch_size=batch_size, num_models=100, number_of_initializations=2, regression=True,\n",
    "                              ))\n",
    "\n",
    "        configs = pd.DataFrame(configs)\n",
    "        # Save as json\n",
    "        configs.to_json(final_path)\n",
    "with open(final_path, 'r') as f:\n",
    "    configs = [data['0'] for data in json.load(f).values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963fddfc",
   "metadata": {},
   "source": [
    "## KFold Cross Validation \n",
    "We perform model selection using the K-fold cross validation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac358d72ea284844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:48:00.104101Z",
     "start_time": "2024-01-09T16:43:58.875811Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_configs = []\n",
    "for config in configs[1]:\n",
    "    config['callbacks'] = ['earlystopping_1e-2_20']\n",
    "if __name__ == '__main__':\n",
    "    my_configs.append(\n",
    "        validate(configs[1], x=training_data, y_true=training_labels, epochs=epochs, return_models_history=True,\n",
    "                          batch_size=batch_size, max_configs=100, number_of_initializations=2, n_splits=4\n",
    "                          ))\n",
    "\n",
    "configs=my_configs[0]\n",
    "old_history = configs[0][0]\n",
    "my_config=configs[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf60c0",
   "metadata": {},
   "source": [
    "## Model Assessment \n",
    "We perform model assessment over the internal test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807cf4472c0504c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:48:05.448923Z",
     "start_time": "2024-01-09T16:48:00.104789Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Composer(config=my_config).compose(regression=True)\n",
    "model.train(inputs=training_data, input_label=training_labels, epochs=epochs, batch_size=batch_size, name=my_config['model_name'], disable_line=False)\n",
    "test_val = model.evaluate(input=test_data, input_label=test_labels, metrics=['mse', 'mee'])\n",
    "results = [(model.get_last()['mse'], np.std(np.array(model.history['mee'])), model.get_last()['mee'], test_val[0], test_val[1], model.curr_epoch, model.best_epoch, np.min(old_history['mee']),  np.min(old_history['val_mee']), old_history['mee'],  old_history['val_mee'], model.history['mee'], Composer(config=my_config).compose(), my_config, my_config['num_layers'], my_config['num_of_units'], my_config['model_name'])]\n",
    "# Convert the list of tuples to a DataFrame with one column for each element in the tuple\n",
    "df = pd.DataFrame(results, columns=['Score', 'History_Std', 'Mee', 'Test_Score', 'Test_Mee', 'Trained_Epochs', 'Old_Best_Epochs', 'Old_History_Last', 'Old_History_val_Last', 'Old_History', 'Old_History_val', 'History', 'Model', 'Config', 'Num_Layers', 'Num_of_Units', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bc786",
   "metadata": {},
   "source": [
    "## Filtering and Ordering Results\n",
    "Sorting the DataFrame by the first element in the tuple (column 'Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fa49d977eb543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:48:05.467145Z",
     "start_time": "2024-01-09T16:48:05.455887Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the first element in the tuple (column 'Value')\n",
    "\n",
    "df_sorted = df.sort_values(by=['Num_Layers', 'Score', 'Test_Score', 'History_Std'])\n",
    "histories = {row[0]: row[1] for row in df_sorted[['Name', 'History']].values}\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef262368c4445b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-09T16:54:03.977646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_history(histories)\n",
    "plot_history(old_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72632ccb74125cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T16:48:05.563607Z",
     "start_time": "2024-01-09T16:48:05.553189Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_least_difference_row(my_df):\n",
    "    min_diff = float('inf')\n",
    "    selected_row = None\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        array = np.array(row['History'])\n",
    "        differences =  (np.diff(array) - np.mean(array)) /np.mean(array) \n",
    "        # differences =  (np.diff(array) / np.mean(array)) \n",
    "        min_consecutive_difference = np.min(differences)\n",
    "\n",
    "        if min_consecutive_difference < min_diff:\n",
    "            min_diff = min_consecutive_difference\n",
    "            selected_row = row\n",
    "\n",
    "    return selected_row\n",
    "\n",
    "# Example usage:\n",
    "result_row = find_least_difference_row(df_sorted)\n",
    "print(\"Selected row:\")\n",
    "print(result_row)\n",
    "print(result_row['Config']) \n",
    "result_row.to_csv('MLCup_FirstTry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e1a5e",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c5a592991ba59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:07:03.718758Z",
     "start_time": "2024-01-09T17:07:03.301714Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history2(name, lines: dict, fig_size=(10, 6)):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for elem in lines:\n",
    "        plt.plot(lines[elem], label=elem)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.savefig(name+'.eps', format='eps')\n",
    "    plt.savefig(name+'.png', format='png')\n",
    "\n",
    "plot_history2(name='MLCup_train', lines={result_row[\"Name\"]: result_row['History']}, fig_size=(10,8))\n",
    "plot_history2(name='MLCup_HoldOut', lines={'HoldOutTrain'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History'])), 'HoldOutTrainVal'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History_val']))}, fig_size=(10,8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5533c9",
   "metadata": {},
   "source": [
    "## Final Retraining\n",
    "We perform the final retraining with the selected models over the entire dataset using hold-out technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf3c3bd46476c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:04:39.093427Z",
     "start_time": "2024-01-09T17:04:33.174157Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset, full_dataset_labels = read_cup_training_dataset('../exclusiveAI/datasets')\n",
    "results = validate(configs[1], x=full_dataset, y_true=full_dataset_labels, max_configs=1, n_splits=4, number_of_initializations=2, epochs=epochs, batch_size=batch_size, regression=True, return_models_history=True)\n",
    "model_config = results[1]\n",
    "\n",
    "model = Composer(config=model_config).compose(regression=True)\n",
    "history = model.train(inputs=full_dataset, input_label=full_dataset_labels, epochs=epochs, batch_size=batch_size)\n",
    "model.save('MLCup_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ea5f589a1daae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:39:14.048569Z",
     "start_time": "2024-01-09T17:38:25.291491Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# histories = results[0]\n",
    "# history_cv = {key: histories[key] for key in histories if 'mee' in  key}\n",
    "# plot_history({key: history[key] for key in history if 'mee' in key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b84f20b9c8f49e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:42:31.244867Z",
     "start_time": "2024-01-09T17:42:31.239437Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from exclusiveAI.components.NeuralNetwork import NeuralNetwork\n",
    "final_model = NeuralNetwork.load('MLCup_model.h5')\n",
    "res = final_model.evaluate(test_data, test_labels, metrics=['mse', 'mee'])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e288857",
   "metadata": {},
   "source": [
    "## Blind Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe84fea3c6c91c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:46:28.797095Z",
     "start_time": "2024-01-09T17:46:28.788466Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset = read_cup_test_dataset('../exclusiveAI/datasets')\n",
    "test_dataset\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0d2d7d7573175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:45:11.557022Z",
     "start_time": "2024-01-09T17:45:11.467273Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = final_model.predict(test_dataset)\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "df.to_csv(\"./final_prediction.csv\", float_format='%.16f', index=True, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76221a5d468b33a8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Monk2 Dataset\n",
    "In this notebook we perform model training, selection and assessment over the Monk 2 Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f565beeebe055d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.005905Z",
     "start_time": "2024-01-08T17:57:39.004634Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from exclusiveAI.components.Validation.HoldOut import parallel_hold_out, hold_out\n",
    "from exclusiveAI.components.Validation.KFoldCrossValidation import validate\n",
    "from exclusiveAI.components.CallBacks import EarlyStoppingCallback\n",
    "from exclusiveAI.ConfiguratorGen import ConfiguratorGen\n",
    "from exclusiveAI.datasets.monk import read_monk2\n",
    "from exclusiveAI.utils import one_hot_encoding\n",
    "from exclusiveAI.Composer import Composer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exclusiveAI.utils import plot_history\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c193fe85cb2214",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fc019",
   "metadata": {},
   "source": [
    "Importing training and test dataset by splitting data and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efbf06487c3d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.031991Z",
     "start_time": "2024-01-08T17:57:39.007699Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, training_labels, test_data, test_labels = read_monk2(\"../exclusiveAI/datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a7c15dc5f0bf3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encoding the training and test data using the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f54f940a1597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.032856Z",
     "start_time": "2024-01-08T17:57:39.012899Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = one_hot_encoding(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ff08be1ee7aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.033158Z",
     "start_time": "2024-01-08T17:57:39.016176Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = one_hot_encoding(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe3b0cb99b46a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Grid Search\n",
    "After having performed a coarse-grained grid search, we perform a fine-grained grid search using the combination of best model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aef1ab1b752912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.051376Z",
     "start_time": "2024-01-08T17:57:39.021742Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_json_files(my_dir_path):\n",
    "        data = pd.DataFrame()\n",
    "        for file in os.listdir(my_dir_path):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(my_dir_path, file), 'r') as f:\n",
    "                    my_data = [data['0'] for data in json.load(f).values()][1]\n",
    "                    data = pd.concat([data,  pd.DataFrame(my_data)], ignore_index=True, axis=0)\n",
    "        return data\n",
    "batch_size = 100\n",
    "epochs = 500\n",
    "\n",
    "final_file = \"monk2_models_configs_hist3.json\"\n",
    "\n",
    "if not os.path.exists(final_file):\n",
    "    dir_path = \"Monk2/\"\n",
    "    \n",
    "    all_json_data = read_json_files(dir_path)\n",
    "    regularizations = all_json_data['regularization'].unique().tolist()\n",
    "    learning_rates = all_json_data['learning_rate'].unique().tolist()\n",
    "    momentums = all_json_data['momentum'].unique().tolist()\n",
    "    num_of_layers = [1]\n",
    "    num_of_units = set([unit1 if unit1!=1 else 2 for unit in all_json_data['num_of_units'] for unit1 in unit])\n",
    "    initializers = all_json_data['initializers'].value_counts().index.tolist()\n",
    "    activations = ['sigmoid', 'tanh']\n",
    "    \n",
    "    # ea = EarlyStoppingCallback(patiente_limit=50, eps=)\n",
    "    # \n",
    "    myConfigurator = ConfiguratorGen(random=False, learning_rates=learning_rates, regularizations=regularizations,\n",
    "                                     loss_function=['mse'], optimizer=['sgd'],\n",
    "                                     activation_functions=activations,\n",
    "                                     number_of_units=num_of_units, number_of_layers=num_of_layers,\n",
    "                                     momentums=momentums, initializers=initializers,\n",
    "                                     input_shapes=training_data.shape,\n",
    "                                     verbose=False, nesterov=True,\n",
    "                                     callbacks=[\"earlystopping\"], output_activation='sigmoid', show_line=False,\n",
    "                                     ).get_configs()\n",
    "    len(myConfigurator)\n",
    "    \n",
    "    configs=[]\n",
    "    if __name__ == '__main__':\n",
    "        configs.append(\n",
    "            parallel_hold_out(myConfigurator, training=training_data, training_target=training_labels, epochs=epochs,\n",
    "                              batch_size=batch_size, num_models=100, workers=-2, number_of_initializations=2, return_models_history=True,\n",
    "                              ))\n",
    "    \n",
    "        configs = pd.DataFrame(configs)\n",
    "        # Save as json\n",
    "        configs.to_json(final_file)\n",
    "else: \n",
    "    with open(final_file, 'r') as f:\n",
    "        configs = [data['0'] for data in json.load(f).values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7972d15",
   "metadata": {},
   "source": [
    "## Hold-out\n",
    "We perform model selection using the hold-out technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5399fbd4955b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:39.051621Z",
     "start_time": "2024-01-08T17:57:39.045489Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_configs = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    my_configs.append(\n",
    "        hold_out(configs[1], training=training_data, training_target=training_labels, epochs=epochs, return_models_history=True,\n",
    "                    batch_size=batch_size, num_models=100, number_of_initializations=2,\n",
    "                      ))\n",
    "\n",
    "configs=my_configs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efe387",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a044eeaffa2f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:40.026341Z",
     "start_time": "2024-01-08T17:57:39.049303Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "old_histories = configs[0]\n",
    "my_configs=configs[1]\n",
    "with tqdm(total=len(my_configs)) as pbar:\n",
    "    for old_hist, config in zip(old_histories, my_configs):\n",
    "        model = Composer(config=config).compose()\n",
    "        model.train(inputs=training_data, input_label=training_labels, val=test_data, val_labels=test_labels, epochs=epochs, batch_size=batch_size, name=config['model_name'], disable_line=True)\n",
    "        test_val = model.evaluate(input=test_data, input_label=test_labels)\n",
    "        models.append((model.get_last()['mse'], np.std(np.array(model.history['mse'])), model.get_last()['binary_accuracy'], test_val[0], test_val[1], model.curr_epoch, old_hist['binary_accuracy'][-1],  old_hist['val_binary_accuracy'][-1], model.history['mse'],  model.history['val_mse'], model.history['mse'], model.history['binary_accuracy'], model.history['val_binary_accuracy'], Composer(config=config).compose(), config, config['num_layers'], config['num_of_units'], config['model_name']))\n",
    "        pbar.update(1)\n",
    "\n",
    "# Convert the list of tuples to a DataFrame with one column for each element in the tuple\n",
    "df = pd.DataFrame(models, columns=['Score', 'History_Std', 'Accuracy', 'Test_Score', 'Test_Accuracy', 'Trained_Epochs', 'Old_Accuracy', 'Old_Accuracy_val', 'Old_History', 'Old_History_val', 'History', 'Accuracy_History', 'Val_Accuracy_History', 'Model', 'Config', 'Num_Layers', 'Num_of_Units', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228a214",
   "metadata": {},
   "source": [
    "## Filtering and Ordering Results\n",
    "Sorting the DataFrame by the first element in the tuple (column 'Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3d5bc54282f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:40.042833Z",
     "start_time": "2024-01-08T17:57:40.028719Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['Num_Layers', 'History_Std', 'Score', 'Test_Score'])\n",
    "df_sorted = df_sorted[df_sorted['Accuracy'] >= 1]\n",
    "df_sorted = df_sorted[df_sorted['Old_Accuracy_val'] >= 1]\n",
    "df_sorted = df_sorted[df_sorted['Old_Accuracy'] >= 1]\n",
    "histories = {row[0]: row[1] for row in df_sorted[['Name', 'History']].values}\n",
    "old_histories = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History']].values}\n",
    "old_histories_val = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History_val']].values}\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683372f",
   "metadata": {},
   "source": [
    "We pick the best models according to low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06acc7b055bed74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T17:57:40.262138Z",
     "start_time": "2024-01-08T17:57:40.257544Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_least_difference_row(my_df):\n",
    "    min_diff = float('inf')\n",
    "    selected_row = None\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        array1 = np.array(row['History'])\n",
    "        # differences1 =  (np.diff(array1) - np.mean(array1)) /np.mean(array1)\n",
    "        differences1 =  (np.diff(array1) / np.mean(array1))\n",
    "        min_consecutive_difference = np.min(differences1)\n",
    "\n",
    "        if min_consecutive_difference < min_diff:\n",
    "            min_diff = min_consecutive_difference\n",
    "            selected_row = row\n",
    "\n",
    "    return selected_row\n",
    "\n",
    "# Example usage:\n",
    "result_row = find_least_difference_row(df_sorted)\n",
    "print(\"Selected row:\")\n",
    "print(result_row)\n",
    "result_row.to_csv('Monk2_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ffa37",
   "metadata": {},
   "source": [
    "## Plots\n",
    "Plotting the final model curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71238466d7a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:19:31.720611Z",
     "start_time": "2024-01-08T18:19:31.241387Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history2(name, lines: dict, fig_size=(10, 6), label='mse'):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for elem in lines:\n",
    "        plt.plot(lines[elem], label=elem)\n",
    "    plt.legend(fontsize='12')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.savefig(name+'.eps', format='eps')\n",
    "    plt.savefig(name+'.png', format='png')\n",
    "\n",
    "# plot_history2(name='Monk1_train', lines={result_row[\"Name\"]: result_row['History']}, fig_size=(10,8))\n",
    "plot_history2(name='Monk2_KFold', lines={'HoldOut Training '+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History'])), 'HoldOut Test '+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History_val']))}, fig_size=(10,8))\n",
    "plot_history2(name='Monk2_Accuracy', lines={result_row[\"Name\"]+\" Accuracy \": result_row['Accuracy_History'], result_row[\"Name\"]+\" Test Accuracy \": result_row['Val_Accuracy_History']}, fig_size=(10,8), label='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8380e5",
   "metadata": {},
   "source": [
    "This is the final configuration we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bd37dbf9af24",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config = {'regularization': 1e-07, 'learning_rate': 0.7, 'loss_function': 'mse', 'activation_functions': ['tanh'], 'output_activation': 'sigmoid', 'num_of_units': [4], 'num_layers': 1, 'momentum': 0.9, 'optimizer': 'sgd', 'initializers': 'uniform', 'nesterov': True, 'input_shape': [169, 17], 'callbacks': ['earlystopping_1e-4_20_False'], 'verbose': False, 'outputs': 1, 'model_name': 'Model221'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

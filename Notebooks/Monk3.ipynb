{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76221a5d468b33a8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Monk3 Dataset\n",
    "In this notebook we perform model training, selection and assessment over the Monk 3 Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f565beeebe055d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.712861Z",
     "start_time": "2024-01-08T18:15:07.692281Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from exclusiveAI.components.Validation.HoldOut import parallel_hold_out, hold_out\n",
    "from exclusiveAI.components.Validation.KFoldCrossValidation import validate\n",
    "from exclusiveAI.ConfiguratorGen import ConfiguratorGen\n",
    "from exclusiveAI.datasets.monk import read_monk3\n",
    "from exclusiveAI.utils import one_hot_encoding\n",
    "from exclusiveAI.Composer import Composer\n",
    "from exclusiveAI.components.CallBacks import EarlyStoppingCallback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exclusiveAI.utils import plot_history\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c193fe85cb2214",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Read Dataset \n",
    "Importing training and test dataset by splitting data and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efbf06487c3d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.713098Z",
     "start_time": "2024-01-08T18:15:07.695964Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, training_labels, test_data, test_labels = read_monk3(\"../exclusiveAI/datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a7c15dc5f0bf3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encoding the training and test data using the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f54f940a1597f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.729251Z",
     "start_time": "2024-01-08T18:15:07.716802Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = one_hot_encoding(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ff08be1ee7aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.729469Z",
     "start_time": "2024-01-08T18:15:07.721430Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = one_hot_encoding(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26c81a871bfa64",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Grid Search\n",
    "After having performed a coarse-grained grid search, we perform a fine-grained grid search using the combination of best model's parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d4687b8384299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.764771Z",
     "start_time": "2024-01-08T18:15:07.726585Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_json_files(my_dir_path):\n",
    "        data = pd.DataFrame()\n",
    "        for file in os.listdir(my_dir_path):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(my_dir_path, file), 'r') as f:\n",
    "                    my_data = [data['0'] for data in json.load(f).values()][1]\n",
    "                    data = pd.concat([data,  pd.DataFrame(my_data)], ignore_index=True, axis=0)\n",
    "        return data\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "\n",
    "final_file = 'monk3_models_configs_hist3.json'\n",
    "\n",
    "if not os.path.exists(final_file):\n",
    "    dir_path = \"Monk3/\"\n",
    "    \n",
    "    all_json_data = read_json_files(dir_path)\n",
    "    regularizations = all_json_data['regularization'].unique().tolist()\n",
    "    learning_rates = all_json_data['learning_rate'].unique().tolist()\n",
    "    learning_rates = set([value if 0.09 < value< 0.25 else 0.1 for value in learning_rates])\n",
    "    # momentums = all_json_data['momentum'].unique().tolist()\n",
    "    momentums = [0.1, 0.2, 0]\n",
    "    num_of_layers = [2]#all_json_data['num_layers'].unique().tolist()\n",
    "    num_of_units = set([unit1 for unit in all_json_data['num_of_units'] for unit1 in unit])\n",
    "    initializers = [\"uniform\", \"gaussian\"]\n",
    "    activations = [\"sigmoid\"]\n",
    "    \n",
    "    myConfigurator = ConfiguratorGen(random=False, learning_rates=learning_rates, regularizations=regularizations,\n",
    "                                     loss_function=['mse'], optimizer=['sgd'],\n",
    "                                     activation_functions=activations,\n",
    "                                     number_of_units=num_of_units, number_of_layers=num_of_layers,\n",
    "                                     momentums=momentums, initializers=initializers,\n",
    "                                     input_shapes=training_data.shape,\n",
    "                                     verbose=False, nesterov=True,\n",
    "                                     callbacks=[\"earlystopping\"], output_activation='linear', show_line=False,\n",
    "                                     ).get_configs()\n",
    "    len(myConfigurator)\n",
    "    \n",
    "    configs=[]\n",
    "    if __name__ == '__main__':\n",
    "        configs.append(\n",
    "            parallel_hold_out(myConfigurator, training=training_data, training_target=training_labels, epochs=epochs, regression=True,\n",
    "                              batch_size=batch_size, num_models=100, workers=4, number_of_initializations=3, return_models_history=True,\n",
    "                              ))\n",
    "    \n",
    "        configs = pd.DataFrame(configs)\n",
    "        # Save as json\n",
    "        configs.to_json(final_file)\n",
    "else: \n",
    "    with open(final_file, 'r') as f:\n",
    "        configs = [data['0'] for data in json.load(f).values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3a933",
   "metadata": {},
   "source": [
    "## Hold-out \n",
    "We perform model selection using the hold-out technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7d636a8ba4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:07.765065Z",
     "start_time": "2024-01-08T18:15:07.744826Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_configs = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    my_configs.append(\n",
    "        hold_out(configs[1], training=training_data, training_target=training_labels, epochs=epochs, return_models_history=True,\n",
    "                       batch_size=batch_size, num_models=100, number_of_initializations=2,\n",
    "                     ))\n",
    " \n",
    "configs=my_configs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a78b3",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b144053f7348102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:08.830012Z",
     "start_time": "2024-01-08T18:15:07.751212Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "old_histories = configs[0]\n",
    "my_configs=configs[1]\n",
    "with tqdm(total=len(my_configs)) as pbar:\n",
    "    for old_hist, config in zip(old_histories, my_configs):\n",
    "        model = Composer(config=config).compose()\n",
    "        model.train(inputs=training_data, input_label=training_labels, val=test_data, val_labels=test_labels, epochs=epochs, batch_size=batch_size, name=config['model_name'], disable_line=True)\n",
    "        test_val = model.evaluate(input=test_data, input_label=test_labels)\n",
    "        models.append((model.get_last()['mse'], np.std(np.array(model.history['mse'])), model.get_last()['binary_accuracy'], test_val[0], test_val[1], model.curr_epoch, max(old_hist['binary_accuracy']),  max(old_hist['val_binary_accuracy']), model.history['mse'],  model.history['mse'], model.history['val_mse'], model.history['binary_accuracy'], model.history['val_binary_accuracy'], Composer(config=config).compose(), config, config['num_layers'], config['num_of_units'], config['model_name']))\n",
    "        pbar.update(1)\n",
    "\n",
    "# Convert the list of tuples to a DataFrame with one column for each element in the tuple\n",
    "df = pd.DataFrame(models, columns=['Score', 'History_Std', 'Accuracy', 'Test_Score', 'Test_Accuracy', 'Trained_Epochs', 'Old_Accuracy', 'Old_Accuracy_val', 'Old_History', 'Old_History_val', 'History', 'Accuracy_History', 'Val_Accuracy_History', 'Model', 'Config', 'Num_Layers', 'Num_of_Units', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a04f7",
   "metadata": {},
   "source": [
    "## Filtering and Ordering Results\n",
    "Sorting the DataFrame by the first element in the tuple (column 'Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0205ce48eb9dc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:08.859472Z",
     "start_time": "2024-01-08T18:15:08.826801Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['Num_Layers', 'Score', 'Test_Score', 'History_Std'])\n",
    "df_sorted = df_sorted[df_sorted['Accuracy'] >= 0.95] \n",
    "df_sorted = df_sorted[df_sorted['Old_Accuracy_val'] >= 0.97]\n",
    "df_sorted = df_sorted[df_sorted['Old_Accuracy'] >= 0.97]\n",
    "histories = {row[0]: row[1] for row in df_sorted[['Name', 'History']].values}\n",
    "old_histories = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History']].values}\n",
    "old_histories_val = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History_val']].values}\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c211da",
   "metadata": {},
   "source": [
    "We pick the best models according to low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89379b1f6c8b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:15:09.108612Z",
     "start_time": "2024-01-08T18:15:09.098277Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_least_difference_row(my_df):\n",
    "    min_diff = float('inf')\n",
    "    selected_row = None\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        array1 = np.array(row['History'])\n",
    "        differences1 =  (np.diff(array1) - np.mean(array1)) /np.mean(array1)\n",
    "        min_consecutive_difference = np.min(differences1)\n",
    "\n",
    "        if min_consecutive_difference < min_diff:\n",
    "            min_diff = min_consecutive_difference\n",
    "            selected_row = row\n",
    "\n",
    "    return selected_row\n",
    "\n",
    "result_row = find_least_difference_row(df_sorted)\n",
    "# Pivot the DataFrame using 'Unnamed: 0' as both index and columns\n",
    "print(result_row)\n",
    "result_row.to_csv('Monk3_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af469b",
   "metadata": {},
   "source": [
    "## Plots\n",
    "Plotting the final model curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4e5a0f1fedea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T18:18:44.916070Z",
     "start_time": "2024-01-08T18:18:44.398310Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history2(name, lines: dict, fig_size=(10, 6), label='mse', line=False):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for i, elem in enumerate(lines):\n",
    "        if line and len(lines) == 2 and i==1:\n",
    "            plt.plot(lines[elem], label=elem, linestyle='dashed', linewidth=6)\n",
    "        else:\n",
    "            plt.plot(lines[elem], label=elem)\n",
    "    plt.legend(fontsize='12')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.savefig(name+'.eps', format='eps')\n",
    "    plt.savefig(name+'.png', format='png')\n",
    "\n",
    "# plot_history2(name='Monk1_train', lines={result_row[\"Name\"]: result_row['History']}, fig_size=(10,8))\n",
    "plot_history2(name='Monk3_KFold', lines={'HoldOut Training '+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History'])), 'HoldOut Test '+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History_val']))}, fig_size=(10,8), line=True)\n",
    "plot_history2(name='Monk3_Accuracy', lines={result_row[\"Name\"]+\" Accuracy \": result_row['Accuracy_History'], result_row[\"Name\"]+\" Test Accuracy \": result_row['Val_Accuracy_History']}, fig_size=(10,8), label='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c223032",
   "metadata": {},
   "source": [
    "This is the final configuration we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874c817917f92e2",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config = {'regularization': 1e-07, 'learning_rate': 0.22, 'loss_function': 'mse', 'activation_functions': ['tanh'], 'output_activation': 'sigmoid', 'num_of_units': [3], 'num_layers': 1, 'momentum': 0.1, 'optimizer': 'sgd', 'initializers': 'uniform', 'nesterov': True, 'input_shape': [122, 17], 'callbacks': ['earlystopping_1e-4_50_False_True'], 'verbose': False, 'outputs': 1, 'model_name': 'Model2427'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
